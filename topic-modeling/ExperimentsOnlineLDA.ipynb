{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython2"
  },
  "name": "",
  "signature": "sha256:79683d2d4e2fe84fb17d08baa8696c7f80b85b0146c072688296f114ab97d154"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Experiments with implementations of OnlineLDA"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import bz2\n",
      "import bz2\n",
      "import os\n",
      "import sys\n",
      "import json\n",
      "import tempfile\n",
      "import subprocess\n",
      "\n",
      "import gensim\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Output Directory"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Time Checker"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "class TimeChecker(object):\n",
      "    \n",
      "    def __enter__(self):\n",
      "        self.start_times = os.times()\n",
      "        return self\n",
      "    \n",
      "    def __exit__(self, type, value, traceback):\n",
      "        pass\n",
      "    \n",
      "    def status(self):\n",
      "        current_times = os.times()\n",
      "        fields = ('utime', 'stime', 'cutime', 'cstime', 'elapsed_time')\n",
      "        return {\n",
      "            field: current_value - start_value\n",
      "            for field, (start_value, current_value) in zip(fields, zip(self.start_times, current_times))\n",
      "        }\n",
      "        \n",
      "import time\n",
      "with TimeChecker() as t:\n",
      "    time.sleep(2)\n",
      "    print t.status()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'elapsed_time': 2.0, 'cutime': 0.0, 'cstime': 0.0, 'stime': 0.0, 'utime': 0.0}\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Gensim Runner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def infer_stochastic_matrix(alphas, a=0, tol=1e-10):\n",
      "    \"\"\"\n",
      "    Infer stochastic matrix from Dirichlet distributions. \n",
      "    \n",
      "    Input: matrix with rows corresponding to parameters of \n",
      "    the asymmetric Dirichlet distributions, parameter a.\n",
      "    \n",
      "    a=0 => expected distributions\n",
      "    a=1 => most probable distributions\n",
      "    a=1/2 => normalized median-marginal distributions\n",
      "    \n",
      "    Returns: inferred stochastic matrix.\n",
      "    \"\"\"\n",
      "    alpha0 = alphas.sum(axis=1, keepdims=True)\n",
      "    A = alphas - a\n",
      "    A[A < tol] = 0\n",
      "    A = A / (A.sum(axis=1, keepdims=True) + 1e-15)\n",
      "    return A\n",
      "\n",
      "def compute_perplexity_artm(corpus, Phi, Theta):\n",
      "    sum_n = 0.0\n",
      "    sum_loglike = 0.0\n",
      "    for doc_id, doc in enumerate(corpus):\n",
      "        for term_id, count in doc:\n",
      "            sum_n += count\n",
      "            sum_loglike += count * np.log( np.dot(Theta[doc_id, :], Phi[:, term_id]) )\n",
      "    perplexity = np.exp(- sum_loglike / sum_n)\n",
      "    return perplexity\n",
      "\n",
      "# def compute_perplexity_vb(corpus, model):\n",
      "#     Gamma, _ = model.inference(corpus)\n",
      "#     for doc_id, doc in enumerate(corpus):\n",
      "#         for term_id, count in doc:\n",
      "#             model.inference\n",
      "#             sum_n += count\n",
      "#             sum_loglike += count * np.log2( np.dot(Theta[doc_id, :], Phi[:, term_id]) )\n",
      "#     return perplexity\n",
      "\n",
      "def run_gensim(name, train, test, wordids='enwiki-20141208-pages-articles_wordids.txt.bz2', **params):\n",
      "    \n",
      "    id2word = gensim.corpora.Dictionary.load_from_text('data/%s' % wordids)\n",
      "    train_corpus = gensim.corpora.MmCorpus('data/%s.mm' % train)\n",
      "    \n",
      "    with TimeChecker() as timer:\n",
      "        model = gensim.models.ldamodel.LdaModel(corpus=train_corpus, id2word=id2word, **params)\n",
      "        train_time = timer.status()\n",
      "    \n",
      "    model.save('target/%s.gensim_model' % name)\n",
      "    \n",
      "    report = {\n",
      "        'train_time': train_time,\n",
      "    }\n",
      "    \n",
      "    Lambda = model.state.get_lambda()\n",
      "    Phi = infer_stochastic_matrix(Lambda, 0)\n",
      "    matrices = {\n",
      "        'Lambda': Lambda,\n",
      "        'Phi_mean': Phi,\n",
      "        'Phi_map': infer_stochastic_matrix(Lambda, 1),\n",
      "    }\n",
      "    \n",
      "    for id, corpus_name in test.iteritems():\n",
      "        test_corpus = gensim.corpora.MmCorpus('data/%s.mm' % corpus_name)\n",
      "\n",
      "        with TimeChecker() as timer:\n",
      "            Gamma, _ = model.inference(test_corpus)\n",
      "            inference_time = timer.status()\n",
      "            \n",
      "        Theta = infer_stochastic_matrix(Gamma, 0)\n",
      "        matrices['%s_Gamma' % id] = Gamma\n",
      "        matrices['%s_Theta_mean' % id] = Theta\n",
      "        matrices['%s_Theta_map' % id] = infer_stochastic_matrix(Gamma, 1)\n",
      "        \n",
      "        report[id] = {\n",
      "            'inference_time': inference_time,\n",
      "            'perplexity_gensim': np.exp(-model.log_perplexity(test_corpus)),\n",
      "#             'perplexity_vb': compute_perplexity_vb(test_corpus, model),\n",
      "            'perplexity_artm': compute_perplexity_artm(test_corpus, Phi, Theta),\n",
      "        }\n",
      "    \n",
      "    with open('target/%s.report.json' % name, 'w') as report_file:\n",
      "        json.dump(report, report_file, indent=2)\n",
      "    np.savez_compressed('target/%s.matrices.npz' % name, **matrices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_gensim(\n",
      "    name='toy_gensim',\n",
      "    train='wiki_bow_toy1',\n",
      "    test={'train': 'wiki_bow_toy1', 'test': 'wiki_bow_toy2'},\n",
      "    num_topics=10, update_every=1, chunksize=100, passes=1, eval_every=0,\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat target/toy_gensim.report.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\r\n",
        "  \"train_time\": {\r\n",
        "    \"elapsed_time\": 8.309999998658895, \r\n",
        "    \"cutime\": 0.0, \r\n",
        "    \"cstime\": 0.0, \r\n",
        "    \"stime\": 0.28, \r\n",
        "    \"utime\": 8.030000000000001\r\n",
        "  }, \r\n",
        "  \"test\": {\r\n",
        "    \"perplexity_artm\": 15843.464748520551, \r\n",
        "    \"perplexity_gensim\": 126498.71397378964, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 2.6200000010430813, \r\n",
        "      \"cutime\": 0.0, \r\n",
        "      \"cstime\": 0.0, \r\n",
        "      \"stime\": 0.0, \r\n",
        "      \"utime\": 2.6200000000000045\r\n",
        "    }\r\n",
        "  }, \r\n",
        "  \"train\": {\r\n",
        "    \"perplexity_artm\": 8709.3221048491177, \r\n",
        "    \"perplexity_gensim\": 28851.305205499077, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 2.169999998062849, \r\n",
        "      \"cutime\": 0.0, \r\n",
        "      \"cstime\": 0.0, \r\n",
        "      \"stime\": 0.0, \r\n",
        "      \"utime\": 2.1599999999999966\r\n",
        "    }\r\n",
        "  }\r\n",
        "}"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat target/toy_gensim.report.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\r\n",
        "  \"train_time\": {\r\n",
        "    \"elapsed_time\": 8.160000000149012, \r\n",
        "    \"cutime\": 0.0, \r\n",
        "    \"cstime\": 0.0, \r\n",
        "    \"stime\": 0.21000000000000002, \r\n",
        "    \"utime\": 7.7700000000000005\r\n",
        "  }, \r\n",
        "  \"test\": {\r\n",
        "    \"perplexity_artm\": 15817.053447143178, \r\n",
        "    \"perplexity_gensim\": 122530.97350010248, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 2.4900000020861626, \r\n",
        "      \"cutime\": 0.0, \r\n",
        "      \"cstime\": 0.0, \r\n",
        "      \"stime\": 0.0, \r\n",
        "      \"utime\": 2.49\r\n",
        "    }\r\n",
        "  }, \r\n",
        "  \"train\": {\r\n",
        "    \"perplexity_artm\": 8896.5975969236097, \r\n",
        "    \"perplexity_gensim\": 28831.020824993215, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 2.149999998509884, \r\n",
        "      \"cutime\": 0.0, \r\n",
        "      \"cstime\": 0.0, \r\n",
        "      \"stime\": 0.0, \r\n",
        "      \"utime\": 2.1400000000000006\r\n",
        "    }\r\n",
        "  }\r\n",
        "}"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Vowpal Wabbit Runner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def read_vw_matrix(filename, topics=False, n_term=None):\n",
      "    with open(filename) as f:\n",
      "        if topics:\n",
      "            for i in xrange(11): f.readline()\n",
      "        result_matrix = []\n",
      "        for line in f:\n",
      "            parts = line.strip().replace('  ', ' ').split(' ')\n",
      "            if topics:\n",
      "                index = int(parts[0])\n",
      "                matrix_line = map(float, parts[1:])\n",
      "                if index < n_term or not n_term:\n",
      "                    result_matrix.append(matrix_line)\n",
      "            else:\n",
      "                index = int(parts[-1])\n",
      "                matrix_line = map(float, parts[:-1])\n",
      "                result_matrix.append(matrix_line)\n",
      "    return np.array(result_matrix, dtype=float)\n",
      "\n",
      "def read_vw_gammas(predictions_path):\n",
      "    gammas = read_vw_matrix(predictions_path, topics=False)\n",
      "    return gammas\n",
      "\n",
      "def read_vw_lambdas(topics_path, n_term=None):\n",
      "    lambdas = read_vw_matrix(topics_path, topics=True, n_term=n_term).T\n",
      "    return lambdas\n",
      "\n",
      "def run_vw(name, train, test, wordids='enwiki-20141208-pages-articles_wordids.txt.bz2', additional_args=[],\n",
      "        num_topics=10, alpha=0.1, rho=0.1, batch_size=256, power_t=0.5, initial_t=1, passes=1):\n",
      "    id2word = gensim.corpora.Dictionary.load_from_text('data/%s' % wordids)\n",
      "    train_corpus = gensim.corpora.MmCorpus('data/%s.mm' % train)\n",
      "    \n",
      "    tempdir = tempfile.mkdtemp()\n",
      "    \n",
      "    cmd = [\n",
      "        'vw',\n",
      "        'data/%s.vw' % train,\n",
      "        '-b', '%.0f' % np.ceil(np.log2(len(id2word))),\n",
      "        '--cache_file', os.path.join(tempdir, 'cache_file'),\n",
      "        '--lda', str(num_topics),\n",
      "        '--lda_alpha', str(alpha),\n",
      "        '--lda_rho', str(rho),\n",
      "        '--lda_D', str(train_corpus.num_docs),\n",
      "        '--minibatch', str(batch_size),\n",
      "        '--power_t', str(power_t),\n",
      "        '--initial_t', str(initial_t),\n",
      "        '--passes', str(passes),\n",
      "        '--readable_model', os.path.join(tempdir, 'readable_model'),\n",
      "        '-p', os.path.join(tempdir, 'predictions'),\n",
      "        '-f', 'target/%s.vw_model' % name,\n",
      "    ] + additional_args\n",
      "    \n",
      "    with TimeChecker() as timer:\n",
      "        proc = subprocess.Popen(cmd)\n",
      "        proc.wait()\n",
      "        train_time = timer.status()\n",
      "    \n",
      "    report = {\n",
      "        'train_time': train_time,\n",
      "    }\n",
      "    \n",
      "    Lambda = read_vw_lambdas(os.path.join(tempdir, 'readable_model'), n_term=len(id2word))\n",
      "    Phi = infer_stochastic_matrix(Lambda, 0)\n",
      "    matrices = {\n",
      "        'Lambda': Lambda,\n",
      "        'Phi_mean': Phi,\n",
      "        'Phi_map': infer_stochastic_matrix(Lambda, 1),\n",
      "    }\n",
      "    \n",
      "    for id, corpus_name in test.iteritems():\n",
      "        test_corpus = gensim.corpora.MmCorpus('data/%s.mm' % corpus_name)\n",
      "\n",
      "        predictions_path = os.path.join(tempdir, 'predictions_%s' % id)\n",
      "        cmd = [\n",
      "            'vw',\n",
      "            'data/%s.vw' % corpus_name,\n",
      "            #'--lda', str(num_topics),\n",
      "            '--minibatch', str(test_corpus.num_docs),\n",
      "            '--initial_regressor', 'target/%s.vw_model' % name,\n",
      "            '-p', predictions_path,\n",
      "        ]\n",
      "        \n",
      "        with TimeChecker() as timer:\n",
      "            proc = subprocess.Popen(cmd)\n",
      "            proc.wait()\n",
      "            inference_time = timer.status()\n",
      "            \n",
      "        Gamma = read_vw_gammas(predictions_path)    \n",
      "        Theta = infer_stochastic_matrix(Gamma, 0)\n",
      "        matrices['%s_Gamma' % id] = Gamma\n",
      "        matrices['%s_Theta_mean' % id] = Theta\n",
      "        matrices['%s_Theta_map' % id] = infer_stochastic_matrix(Gamma, 1)\n",
      "        \n",
      "        report[id] = {\n",
      "            'inference_time': inference_time,\n",
      "#             'perplexity_vb': compute_perplexity_vb(test_corpus, model),\n",
      "            'perplexity_artm': compute_perplexity_artm(test_corpus, Phi, Theta),\n",
      "        }\n",
      "    \n",
      "    with open('target/%s.report.json' % name, 'w') as report_file:\n",
      "        json.dump(report, report_file, indent=2)\n",
      "    np.savez_compressed('target/%s.matrices.npz' % name, **matrices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "' '.join(['vw', 'data/wiki_bow_toy2.vw', '--lda', '10', '--minibatch', '1000', '--initial_regressor', 'target/toy_vw.vw_model', '-p', '/tmp/tmpI5VxEg/predictions_test'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "'vw data/wiki_bow_toy2.vw --lda 10 --minibatch 1000 --initial_regressor target/toy_vw.vw_model -p /tmp/tmpI5VxEg/predictions_test'"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_vw(\n",
      "    name='toy_vw',\n",
      "    train='wiki_bow_toy1',\n",
      "    test={'train': 'wiki_bow_toy1', 'test': 'wiki_bow_toy2'},\n",
      "    num_topics=10, alpha=0.1, rho=0.1, batch_size=100, power_t=0.5, initial_t=1, passes=1,\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat target/toy_vw.report.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\r\n",
        "  \"train_time\": {\r\n",
        "    \"elapsed_time\": 1.2400000020861626, \r\n",
        "    \"cutime\": 1.2100000000000009, \r\n",
        "    \"cstime\": 0.04999999999999993, \r\n",
        "    \"stime\": 0.0, \r\n",
        "    \"utime\": 0.0\r\n",
        "  }, \r\n",
        "  \"test\": {\r\n",
        "    \"perplexity_artm\": 17591.143252394751, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 0.6400000005960464, \r\n",
        "      \"cutime\": 0.5800000000000001, \r\n",
        "      \"cstime\": 0.050000000000000044, \r\n",
        "      \"stime\": 0.010000000000000009, \r\n",
        "      \"utime\": 0.0\r\n",
        "    }\r\n",
        "  }, \r\n",
        "  \"train\": {\r\n",
        "    \"perplexity_artm\": 10700.895153595297, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 0.6400000005960464, \r\n",
        "      \"cutime\": 0.5999999999999996, \r\n",
        "      \"cstime\": 0.04999999999999993, \r\n",
        "      \"stime\": 0.010000000000000009, \r\n",
        "      \"utime\": 0.010000000000005116\r\n",
        "    }\r\n",
        "  }\r\n",
        "}"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Run BigARTM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BIGARTM_PATH = '/home/romovpa/bigartm'\n",
      "BIGARTM_BUILD_PATH = '/home/romovpa/bigartm/build'\n",
      "\n",
      "sys.path.append(os.path.join(BIGARTM_PATH, 'src/python'))\n",
      "os.environ['ARTM_SHARED_LIBRARY'] = os.path.join(BIGARTM_BUILD_PATH, 'src/artm/libartm.so')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import artm.messages_pb2, artm.library, sys, time, random, glob, math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name = 'wiki_bigartm'\n",
      "\n",
      "num_topics = 100\n",
      "num_processors = 1\n",
      "numInnerIters = 20\n",
      "batch_size = 10000\n",
      "update_every = 1\n",
      "\n",
      "kappa = 0.5\n",
      "tau0 = 64\n",
      "\n",
      "alpha = 1.0 / num_topics\n",
      "beta  = 1.0 / num_topics\n",
      "\n",
      "train_batches_folder = 'data/wiki_bow_train_batch_10k/'\n",
      "test_batches_folder = 'data/wiki_bow_test_batch_10k/'\n",
      "\n",
      "unique_tokens = artm.library.Library().LoadDictionary(train_batches_folder + 'dictionary')\n",
      "\n",
      "master_config = artm.messages_pb2.MasterComponentConfig()\n",
      "master_config.processors_count = num_processors\n",
      "master_config.cache_theta = True\n",
      "master_config.disk_path = train_batches_folder\n",
      "\n",
      "perplexity_collection_config = artm.messages_pb2.PerplexityScoreConfig()\n",
      "perplexity_collection_config.model_type = artm.library.PerplexityScoreConfig_Type_UnigramCollectionModel\n",
      "#perplexity_collection_config.model_type = artm.library.PerplexityScoreConfig_Type_UnigramDocumentModel\n",
      "perplexity_collection_config.dictionary_name = unique_tokens.name\n",
      "\n",
      "# === TRAIN TOPIC MODEL ================================================================================================\n",
      "with artm.library.MasterComponent(master_config) as master:\n",
      "    dictionary = master.CreateDictionary(unique_tokens)\n",
      "    perplexity_score = master.CreatePerplexityScore(config = perplexity_collection_config)\n",
      "    smooth_sparse_phi = master.CreateSmoothSparsePhiRegularizer()\n",
      "    smooth_sparse_theta = master.CreateSmoothSparseThetaRegularizer()\n",
      "\n",
      "    items_processed_score = master.CreateItemsProcessedScore()\n",
      "\n",
      "    # Configure the model\n",
      "    model = master.CreateModel(config=artm.messages_pb2.ModelConfig(),\n",
      "                               topics_count=num_topics, inner_iterations_count=numInnerIters)\n",
      "    model.EnableScore(items_processed_score)\n",
      "    model.EnableRegularizer(smooth_sparse_phi, beta)\n",
      "    model.EnableRegularizer(smooth_sparse_theta, alpha)\n",
      "\n",
      "    model.Initialize(dictionary)    # Initialize random\n",
      "\n",
      "    with TimeChecker() as timer:\n",
      "\n",
      "        start_time = time.time()\n",
      "        master.InvokeIteration(1)       # Invoke one scan of the entire collection\n",
      "\n",
      "        done = False\n",
      "        first_sync = True\n",
      "        next_items_processed = (batch_size * update_every)\n",
      "        while (not done):\n",
      "            done = master.WaitIdle(10)    # Wait 10 ms and check if the number of processed items had changed\n",
      "            current_items_processed = items_processed_score.GetValue(model).value\n",
      "            if done or (current_items_processed >= next_items_processed):\n",
      "                update_count = current_items_processed / (batch_size * update_every)\n",
      "                next_items_processed = current_items_processed + (batch_size * update_every)      # set next model update\n",
      "                rho = pow(tau0 + update_count, -kappa)                                            # calculate rho\n",
      "                model.Synchronize(decay_weight=(0 if first_sync else (1-rho)), apply_weight=rho)  # synchronize model\n",
      "                first_sync = False\n",
      "                print \"Items processed : %i \" % current_items_processed,\n",
      "                print \"Elapsed time : %.3f \" % (time.time() - start_time)\n",
      "        \n",
      "        report = {'train_time': timer.status()}\n",
      "        with open('target/%s.report.json' % name, 'w') as report_file:\n",
      "            json.dump(report, report_file)\n",
      "                \n",
      "    print \"Saving topic model... \",\n",
      "    with open('target/%s.bigartm_model' % name, 'wb') as binary_file:\n",
      "        binary_file.write(master.GetTopicModel(model).SerializeToString())\n",
      "    print \"Done. \"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_batches_folder = 'data/wiki_bow_test_batch_10k/'\n",
      "\n",
      "# === TEST TOPIC MODEL =================================================================================================\n",
      "test_master_config = artm.messages_pb2.MasterComponentConfig()\n",
      "test_master_config.CopyFrom(master_config)\n",
      "test_master_config.disk_path = test_batches_folder\n",
      "with artm.library.MasterComponent(test_master_config) as test_master:\n",
      "    print \"Loading topic model... \",\n",
      "    topic_model = artm.messages_pb2.TopicModel()\n",
      "    with open('target/%s.bigartm_model' % name, 'rb') as binary_file:\n",
      "        topic_model.ParseFromString(binary_file.read())\n",
      "    print \"Done. \"\n",
      "\n",
      "    test_dictionary = test_master.CreateDictionary(unique_tokens)\n",
      "    test_perplexity_score = test_master.CreatePerplexityScore(config = perplexity_collection_config)\n",
      "    smooth_sparse_phi = test_master.CreateSmoothSparsePhiRegularizer()\n",
      "    smooth_sparse_theta = test_master.CreateSmoothSparseThetaRegularizer()\n",
      "\n",
      "    test_model = test_master.CreateModel(topics_count = num_topics, inner_iterations_count = numInnerIters)\n",
      "    test_model.EnableScore(test_perplexity_score)\n",
      "    test_model.EnableRegularizer(smooth_sparse_phi, beta)\n",
      "    test_model.EnableRegularizer(smooth_sparse_theta, alpha)\n",
      "    test_model.Overwrite(topic_model)  # restore previously saved topic model into test_master\n",
      "\n",
      "    print 'Estimate perplexity on held out batches... '\n",
      "    perplexity = 0.0; perplexity_norm = 0.0\n",
      "    for test_batch_filename in glob.glob(test_batches_folder + \"*.batch\"):\n",
      "        test_batch = artm.library.Library().LoadBatch(test_batch_filename)\n",
      "        test_batch_theta = test_master.GetThetaMatrix(model=test_model, batch=test_batch)\n",
      "        #theta_sparsity = calc_theta_sparsity(test_batch_theta)\n",
      "        #(batch_perplexity, batch_perplexity_norm) = calc_perplexity(topic_model, test_batch_theta, test_batch)\n",
      "        print \"Batch = \" + test_batch_filename,\n",
      "        print \", Theta sparsity = \" + str(theta_sparsity),\n",
      "        print \", Perplexity = \" + str(math.exp(-batch_perplexity / batch_perplexity_norm))\n",
      "        perplexity += batch_perplexity; perplexity_norm += batch_perplexity_norm\n",
      "    print \"Overall test perplexity = \" + str(math.exp(-perplexity / perplexity_norm))\n",
      "\n",
      "    test_master.InvokeIteration()\n",
      "    test_master.WaitIdle()\n",
      "    print \"Test Perplexity calculated in BigARTM = %.3f\" % test_perplexity_score.GetValue(test_model).value\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading topic model...  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done. \n",
        "Estimate perplexity on held out batches... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'calc_theta_sparsity' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-62-87226acabaea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mtest_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0martm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batch_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mtest_batch_theta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_master\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetThetaMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mtheta_sparsity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_theta_sparsity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batch_theta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mbatch_perplexity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_perplexity_norm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_perplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_batch_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Batch = \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtest_batch_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'calc_theta_sparsity' is not defined"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat target/wiki_bigartm.report.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\"train_time\": {\"elapsed_time\": 3715.120000001043, \"cutime\": 0.0, \"cstime\": 0.0, \"stime\": 122.58000000000004, \"utime\": 4422.27}}"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    # Perform one iteration to calculate Perplexity on the entire train dataset\n",
      "    # model.EnableScore(perplexity_score)\n",
      "    # master.InvokeIteration()\n",
      "    # master.WaitIdle()\n",
      "    # print \"Train Perplexity calculated in BigARTM = %.3f\" % perplexity_score.GetValue(model).value\n",
      "\n",
      "# === TEST TOPIC MODEL =================================================================================================\n",
      "# test_master_config = artm.messages_pb2.MasterComponentConfig()\n",
      "# test_master_config.CopyFrom(master_config)\n",
      "# test_master_config.disk_path = test_batches_folder\n",
      "# with artm.library.MasterComponent(test_master_config) as test_master:\n",
      "#     print \"Loading topic model... \",\n",
      "#     topic_model = artm.messages_pb2.TopicModel()\n",
      "#     with open(\"Output.topic_model\", \"rb\") as binary_file:\n",
      "#         topic_model.ParseFromString(binary_file.read())\n",
      "#     print \"Done. \"\n",
      "\n",
      "#     test_dictionary = test_master.CreateDictionary(unique_tokens)\n",
      "#     test_perplexity_score = test_master.CreatePerplexityScore(config = perplexity_collection_config)\n",
      "#     smooth_sparse_phi = test_master.CreateSmoothSparsePhiRegularizer()\n",
      "#     smooth_sparse_theta = test_master.CreateSmoothSparseThetaRegularizer()\n",
      "\n",
      "#     test_model = test_master.CreateModel(topics_count = numTopics, inner_iterations_count = numInnerIters)\n",
      "#     test_model.EnableScore(test_perplexity_score)\n",
      "#     test_model.EnableRegularizer(smooth_sparse_phi, beta)\n",
      "#     test_model.EnableRegularizer(smooth_sparse_theta, alpha)\n",
      "#     test_model.Overwrite(topic_model)  # restore previously saved topic model into test_master\n",
      "\n",
      "#     print 'Estimate perplexity on held out batches... '\n",
      "#     perplexity = 0.0; perplexity_norm = 0.0\n",
      "#     for test_batch_filename in glob.glob(test_batches_folder + \"*.batch\"):\n",
      "#         test_batch = artm.library.Library().LoadBatch(test_batch_filename)\n",
      "#         test_batch_theta = test_master.GetThetaMatrix(model=test_model, batch=test_batch)\n",
      "#         theta_sparsity = calc_theta_sparsity(test_batch_theta)\n",
      "#         (batch_perplexity, batch_perplexity_norm) = calc_perplexity(topic_model, test_batch_theta, test_batch)\n",
      "#         print \"Batch = \" + test_batch_filename,\n",
      "#         print \", Theta sparsity = \" + str(theta_sparsity),\n",
      "#         print \", Perplexity = \" + str(math.exp(-batch_perplexity / batch_perplexity_norm))\n",
      "#         perplexity += batch_perplexity; perplexity_norm += batch_perplexity_norm\n",
      "#     print \"Overall test perplexity = \" + str(math.exp(-perplexity / perplexity_norm))\n",
      "\n",
      "#     test_master.InvokeIteration()\n",
      "#     test_master.WaitIdle()\n",
      "#     print \"Test Perplexity calculated in BigARTM = %.3f\" % test_perplexity_score.GetValue(test_model).value\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def run_bigartm(name, train, test, wordids='enwiki-20141208-pages-articles_wordids.txt.bz2', **params):\n",
      "    \n",
      "    id2word = gensim.corpora.Dictionary.load_from_text('data/%s' % wordids)\n",
      "    train_corpus = gensim.corpora.MmCorpus('data/%s.mm' % train)\n",
      "    \n",
      "    \n",
      "    \n",
      "    with TimeChecker() as timer:\n",
      "        model = gensim.models.ldamodel.LdaModel(corpus=train_corpus, id2word=id2word, **params)\n",
      "        train_time = timer.status()\n",
      "    \n",
      "    model.save('target/%s.gensim_model' % name)\n",
      "    \n",
      "    report = {\n",
      "        'train_time': train_time,\n",
      "    }\n",
      "    \n",
      "    Lambda = model.state.get_lambda()\n",
      "    Phi = infer_stochastic_matrix(Lambda, 0)\n",
      "    matrices = {\n",
      "        'Lambda': Lambda,\n",
      "        'Phi_mean': Phi,\n",
      "        'Phi_map': infer_stochastic_matrix(Lambda, 1),\n",
      "    }\n",
      "    \n",
      "    for id, corpus_name in test.iteritems():\n",
      "        test_corpus = gensim.corpora.MmCorpus('data/%s.mm' % corpus_name)\n",
      "\n",
      "        with TimeChecker() as timer:\n",
      "            Gamma, _ = model.inference(test_corpus)\n",
      "            inference_time = timer.status()\n",
      "            \n",
      "        Theta = infer_stochastic_matrix(Gamma, 0)\n",
      "        matrices['%s_Gamma' % id] = Gamma\n",
      "        matrices['%s_Theta_mean' % id] = Theta\n",
      "        matrices['%s_Theta_map' % id] = infer_stochastic_matrix(Gamma, 1)\n",
      "        \n",
      "        report[id] = {\n",
      "            'inference_time': inference_time,\n",
      "            'perplexity_gensim': np.exp(-model.log_perplexity(test_corpus)),\n",
      "#             'perplexity_vb': compute_perplexity_vb(test_corpus, model),\n",
      "            'perplexity_artm': compute_perplexity_artm(test_corpus, Phi, Theta),\n",
      "        }\n",
      "    \n",
      "    with open('target/%s.report.json' % name, 'w') as report_file:\n",
      "        json.dump(report, report_file, indent=2)\n",
      "    np.savez_compressed('target/%s.matrices.npz' % name, **matrices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Run!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_gensim(\n",
      "    name='wiki_gensim',\n",
      "    train='wiki_bow_train',\n",
      "    test={'valid': 'wiki_bow_valid', 'test': 'wiki_bow_test'},\n",
      "    num_topics=100, update_every=1, chunksize=10000, passes=1, eval_every=0,\n",
      ")\n",
      "\n",
      "run_vw(\n",
      "    name='wiki_vw',\n",
      "    train='wiki_bow_train',\n",
      "    test={'valid': 'wiki_bow_valid', 'test': 'wiki_bow_test'},\n",
      "    num_topics=100, alpha=0.1, rho=0.1, batch_size=10000, power_t=0.5, initial_t=1, passes=1,\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '!'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "!\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat target/wiki_gensim.report.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\r\n",
        "  \"train_time\": {\r\n",
        "    \"elapsed_time\": 22147.150000002235, \r\n",
        "    \"cutime\": 0.0, \r\n",
        "    \"cstime\": 0.0, \r\n",
        "    \"stime\": 425.54, \r\n",
        "    \"utime\": 21719.18\r\n",
        "  }, \r\n",
        "  \"test\": {\r\n",
        "    \"perplexity_artm\": 4160.9746585105322, \r\n",
        "    \"perplexity_gensim\": 6225.980683251918, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 394.910000000149, \r\n",
        "      \"cutime\": 0.0, \r\n",
        "      \"cstime\": 0.0, \r\n",
        "      \"stime\": 0.5, \r\n",
        "      \"utime\": 394.40999999999985\r\n",
        "    }\r\n",
        "  }, \r\n",
        "  \"valid\": {\r\n",
        "    \"perplexity_artm\": 4173.6346021669106, \r\n",
        "    \"perplexity_gensim\": 6213.9855939685367, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 395.339999999851, \r\n",
        "      \"cutime\": 0.0, \r\n",
        "      \"cstime\": 0.0, \r\n",
        "      \"stime\": 0.4800000000000182, \r\n",
        "      \"utime\": 394.8600000000006\r\n",
        "    }\r\n",
        "  }\r\n",
        "}"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat target/wiki_vw.report.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\r\n",
        "  \"train_time\": {\r\n",
        "    \"elapsed_time\": 4355.400000002235, \r\n",
        "    \"cutime\": 4324.1900000000005, \r\n",
        "    \"cstime\": 81.18, \r\n",
        "    \"stime\": 0.040000000000020464, \r\n",
        "    \"utime\": 0.20999999999912689\r\n",
        "  }, \r\n",
        "  \"test\": {\r\n",
        "    \"perplexity_artm\": 4108.1948415425095, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 119.86999999731779, \r\n",
        "      \"cutime\": 114.17000000000007, \r\n",
        "      \"cstime\": 6.329999999999998, \r\n",
        "      \"stime\": 0.01999999999998181, \r\n",
        "      \"utime\": 0.0\r\n",
        "    }\r\n",
        "  }, \r\n",
        "  \"valid\": {\r\n",
        "    \"perplexity_artm\": 4123.9802182831299, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 119.23999999836087, \r\n",
        "      \"cutime\": 115.31999999999971, \r\n",
        "      \"cstime\": 4.519999999999996, \r\n",
        "      \"stime\": 0.01999999999998181, \r\n",
        "      \"utime\": 0.00999999999839929\r\n",
        "    }\r\n",
        "  }\r\n",
        "}"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}