{
 "metadata": {
  "name": "",
  "signature": "sha256:caa0ef17438f093404b35c6603435401410ac8f0c2a7e8cae3765cbbd340ec0e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "BigARTM configuration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "\n",
      "BIGARTM_PATH = '/home/romovpa/bigartm'\n",
      "BIGARTM_BUILD_PATH = '/home/romovpa/bigartm/build'\n",
      "\n",
      "sys.path.append(os.path.join(BIGARTM_PATH, 'src/python'))\n",
      "os.environ['ARTM_SHARED_LIBRARY'] = os.path.join(BIGARTM_BUILD_PATH, 'src/artm/libartm.so')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 01: Synthetic Collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import artm.messages_pb2, artm.library, sys, time, random, glob, math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate small collection of random items\n",
      "num_tokens = 60\n",
      "num_items = 100\n",
      "batch = artm.messages_pb2.Batch()\n",
      "for token_id in range(0, num_tokens):\n",
      "  batch.token.append('token' + str(token_id))\n",
      "\n",
      "for item_id in range(0, num_items):\n",
      "  item = batch.item.add()\n",
      "  item.id = item_id\n",
      "  field = item.field.add()\n",
      "  for token_id in range(0, num_tokens):\n",
      "    field.token_id.append(token_id)\n",
      "    background_count = random.randint(1, 5) if (token_id >= 40) else 0\n",
      "    topical_count    = 10 if ((token_id < 40) and ((token_id % 10) == (item_id % 10))) else 0\n",
      "    field.token_count.append(background_count + topical_count)\n",
      "\n",
      "# Create master component and infer topic model\n",
      "with artm.library.MasterComponent() as master:\n",
      "  master.AddBatch(batch)\n",
      "  perplexity_score = master.CreatePerplexityScore()\n",
      "  top_tokens_score = master.CreateTopTokensScore(num_tokens = 4)\n",
      "  model = master.CreateModel(topics_count = 10, inner_iterations_count = 10)\n",
      "  model.EnableScore(perplexity_score)\n",
      "  model.EnableScore(top_tokens_score)\n",
      "\n",
      "  for iter in range(0, 10):\n",
      "    master.InvokeIteration(1)        # Invoke one scan of the entire collection...\n",
      "    master.WaitIdle();               # and wait until it completes.\n",
      "    model.Synchronize();             # Synchronize topic model.\n",
      "    print \"Iter#\" + str(iter) + \": Perplexity = %.3f\" % perplexity_score.GetValue(model).value\n",
      "\n",
      "  top_tokens = top_tokens_score.GetValue(model)\n",
      "\n",
      "artm.library.Visualizers.PrintTopTokensScore(top_tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "libartm.so: cannot open shared object file: No such file or directory, fall back to ARTM_SHARED_LIBRARY environment variable\n",
        "Iter#0: Perplexity = 0.000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter#1: Perplexity = 56.274\n",
        "Iter#2: Perplexity = 38.058\n",
        "Iter#3: Perplexity = 27.925\n",
        "Iter#4: Perplexity = 23.575\n",
        "Iter#5: Perplexity = 21.956\n",
        "Iter#6: Perplexity = 21.675\n",
        "Iter#7: Perplexity = 21.632"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter#8: Perplexity = 21.614\n",
        "Iter#9: Perplexity = 21.606\n",
        "\n",
        "Top tokens per topic: \n",
        "Topic#1:  token46(0.21)  token43(0.17)  token53(0.09)  token44(0.06)  \n",
        "Topic#5:  token30(0.11)  token20(0.11)  token10(0.11)  token0(0.11)  \n",
        "Topic#9:  token8(0.10)  token38(0.10)  token28(0.10)  token18(0.10)  \n",
        "Topic#13:  token32(0.11)  token22(0.11)  token2(0.11)  token12(0.11)  \n",
        "Topic#17:  token7(0.11)  token27(0.11)  token37(0.11)  token17(0.11)  \n",
        "Topic#21:  token5(0.11)  token35(0.11)  token25(0.11)  token15(0.11)  \n",
        "Topic#25:  token23(0.12)  token3(0.12)  token33(0.12)  token13(0.12)  \n",
        "Topic#29:  token6(0.10)  token36(0.10)  token26(0.10)  token16(0.10)  \n",
        "Topic#33:  token39(0.05)  token19(0.05)  token9(0.05)  token29(0.05)  \n",
        "Topic#37:  token31(0.11)  token21(0.11)  token11(0.11)  token1(0.11) \n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "master"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'master' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-c963080767f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmaster\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'master' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}